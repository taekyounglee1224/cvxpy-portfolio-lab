{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import yfinance as yf\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation 1 : Estimation Error in $\\hat{V}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM1_CFG = dict(\n",
    "    sigma=0.0125,\n",
    "    rho_grid=[0.0, 0.25, 0.5, 0.75],\n",
    "    d_z=10,\n",
    "    d_x=10,\n",
    "    res_grid=[5, 10, 20],\n",
    "    snr_grid=[0.001, 0.002, 0.003, 0.004, 0.005, 0.01, 0.05, 0.10],\n",
    "    n_total=2000,\n",
    "    n_train=1000,\n",
    "    n_test=1000,\n",
    "    n_reps=100,\n",
    "    delta=1.0,\n",
    "    cov_structure=\"toeplitz_rho_absdiff\",\n",
    "    x_dist=\"normal\",\n",
    "    theta0_dist=\"normal\",\n",
    "    snr_matching=\"scale_tau_per_snr\",\n",
    "    mvo_case=\"equality\",          # 1^T z = 1\n",
    "    vhat_mode=\"single_per_split\", # estimation error 주입 방식\n",
    "    vhat_estimator=\"sample_cov\",\n",
    ")\n",
    "SIM1_CFG[\"s_grid\"] = [r * SIM1_CFG[\"d_z\"] for r in SIM1_CFG[\"res_grid\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) ~ (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_V(d, sigma, rho):\n",
    "    idx = torch.arange(d)\n",
    "    dist = (idx[:, None] - idx[None, :]).abs()\n",
    "    V = (sigma ** 2) * (rho ** dist)\n",
    "    return V\n",
    "\n",
    "\n",
    "\n",
    "def compute_tau(signal, V, target_snr):\n",
    "    # signal = (n,d) / Var(d, d)\n",
    "    var_signal = signal.var(unbiased = False)\n",
    "    var_eps = torch.trace(V) / V.shape[0]\n",
    "    tau = torch.sqrt(var_signal / (target_snr * var_eps))\n",
    "    return tau\n",
    "\n",
    "\n",
    "def generate_sim1(cfg, rho, snr, s_cov, seed = 0, device = 'cpu'):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    d = cfg[\"d_z\"]\n",
    "    n_total = cfg[\"n_total\"]\n",
    "    n_train = cfg[\"n_train\"]\n",
    "\n",
    "    # (1) Ground Truth Coefficients\n",
    "    theta0 = torch.randn(d, device = device)\n",
    "\n",
    "    # (2) x ~ N(0, I)\n",
    "    x = torch.randn(n_total, d, device = device)\n",
    "    V = make_V(d, cfg[\"sigma\"], rho).to(device)\n",
    "\n",
    "    # (3) tau 생성, eps ~ N(0, V) 샘플링\n",
    "    signal = x * theta0\n",
    "    tau = compute_tau(signal, V, snr)\n",
    "\n",
    "    L = torch.linalg.cholesky(V)\n",
    "    z = torch.randn(n_total, d, device = device)\n",
    "    eps = z @ L.T  \n",
    "\n",
    "    y = signal + tau * eps\n",
    "\n",
    "    # (4) Train-Test Split\n",
    "    x_train, y_train = x[:n_train], y[:n_train]\n",
    "    x_test, y_test = x[n_train:], y[n_train:]\n",
    "\n",
    "    # (5) Generate Estimates of V\n",
    "    idx = torch.randperm(n_train, device = device)[:s_cov]\n",
    "    Y_s = y_train[idx]\n",
    "    Yc = Y_s - Y_s.mean(dim = 0, keepdim = True)\n",
    "    Vhat = (Yc.T @ Yc) / (s_cov - 1)\n",
    "\n",
    "    return V, Vhat, theta0, x_train, y_train, x_test, y_test, tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 실행 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V_shape:  torch.Size([10, 10])\n",
      "Vhat shape:  torch.Size([10, 10])\n",
      "tau:  956.8330078125\n",
      "train:  torch.Size([1000, 10]) torch.Size([1000, 10]) test:  torch.Size([1000, 10]) torch.Size([1000, 10])\n",
      "Empirical SNR: 0.004950998816639185\n"
     ]
    }
   ],
   "source": [
    "cfg = SIM1_CFG\n",
    "\n",
    "V, Vhat, theta0, x_tr, y_tr, x_te, y_te, tau = generate_sim1(\n",
    "    cfg = cfg,\n",
    "    rho = 0.5,\n",
    "    snr = 0.005,\n",
    "    s_cov = 100,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "print(\"V_shape: \", V.shape)\n",
    "print(\"Vhat shape: \", Vhat.shape)\n",
    "print(\"tau: \", tau.item())\n",
    "print(\"train: \", x_tr.shape, y_tr.shape, \"test: \", x_te.shape, y_te.shape)\n",
    "\n",
    "signal_tr = x_tr * theta0\n",
    "noise_tr  = y_tr - signal_tr\n",
    "\n",
    "emp_snr = signal_tr.var(unbiased=False) / noise_tr.var(unbiased=False)\n",
    "print(\"Empirical SNR:\", emp_snr.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) OLS 계수 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "train MSE: 145.52479553222656\n"
     ]
    }
   ],
   "source": [
    "def fit_ols_univariate(x_train, y_train, eps = 1e-12):\n",
    "    num = (x_train * y_train).sum(dim = 0)\n",
    "    den = (x_train * x_train).sum(dim = 0)\n",
    "    theta_hat = num / (den + eps)\n",
    "\n",
    "    return theta_hat\n",
    "\n",
    "\n",
    "def predict_univariate(x, theta_hat):\n",
    "    return x * theta_hat\n",
    "\n",
    "\n",
    "theta_ols = fit_ols_univariate(x_tr, y_tr)\n",
    "print(theta_ols.shape)\n",
    "\n",
    "yhat_tr = predict_univariate(x_tr, theta_ols)\n",
    "mse_tr = ((yhat_tr - y_tr)**2).mean().item()\n",
    "print(\"train MSE:\", mse_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_F_and_z0(d, device= 'cpu'):\n",
    "    one = torch.ones(d, device = device)\n",
    "    z0 = one / d\n",
    "\n",
    "    R = torch.randn(d, d-1, device = device)\n",
    "    R = R - one[:, None] * (one @ R) / (one @ one)\n",
    "    Q, _ = torch.linalg.qr(R)\n",
    "    F = Q\n",
    "\n",
    "    return F, z0\n",
    "\n",
    "\n",
    "def fit_ipo_eq(x_train, y_train, V, Vhat, delta = 1.0, ridge = 1e-10):\n",
    "    device = x_train.device\n",
    "    m, d = x_train.shape\n",
    "\n",
    "    F, z0 = make_F_and_z0(d, device = device)\n",
    "\n",
    "    mid = torch.linalg.inv(F.T @ Vhat @ F)\n",
    "    G = F @ mid @ F.T\n",
    "\n",
    "    I = torch.eye(d, device = device)\n",
    "\n",
    "    A = G @ V @ G\n",
    "    b = V @ (I - G @ Vhat) @ z0\n",
    "\n",
    "    Heq = torch.zeros(d, d, device = device)\n",
    "    deq = torch.zeros(d, device = device)\n",
    "\n",
    "    for i in range(m):\n",
    "        x = x_train[i]\n",
    "        y = y_train[i]\n",
    "\n",
    "        Heq += (x[:, None] * A * x[None, :])\n",
    "        deq += x * (G @ (y - b))\n",
    "\n",
    "    Heq = Heq / (m * delta)\n",
    "    deq = deq / (m * delta)\n",
    "\n",
    "    Heq = Heq + ridge * torch.eye(d, device=device)\n",
    "\n",
    "    theta_ipo = torch.linalg.solve(Heq, deq)\n",
    "    return theta_ipo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
